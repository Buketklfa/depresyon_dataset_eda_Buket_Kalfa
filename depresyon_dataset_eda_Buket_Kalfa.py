# -*- coding: utf-8 -*-
"""depresyon_dataset_EDA_

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/depresyon-dataset-eda-e4d2d70e-a588-4635-80a6-5d1a36497301.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241123/auto/storage/goog4_request%26X-Goog-Date%3D20241123T203027Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D098343929dfc822d1392775cd8a5e0df5fae8f71e24832de4ced66d3772b7d78ae64ed6b0ddfed71b7d66fff4af670d52cea5f57feda0534be865b7f9ef4be41da1bc2c97cd9077dbee3cdece071f0599d70c1562267a5c11d56b1c274724191e56ac133a07f596018fa14a1473a6a005ad124bcdecc52fae223368ddf10028136beb8294514f09ee07f0ae54062b9a46bb649336ba5f5b7bcc2fdd3e40ecb66f9657f4d6cd4359558395aa01854fe7659cbb93c636baa44519c9b592837e565aa87f8067e8d386b7a45c1a0649a1cd8fd536dbf5960249112e5b20fbdad906ce102ff890e1bfb96f063ba0f359548e20df37b29181fc991a239856f3ea38ef1
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
anthonytherrien_depression_dataset_path = kagglehub.dataset_download('anthonytherrien/depression-dataset')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""**Veri Kümesi Hakkında**
> Veri Kümesi Genel Bakış (Sentetik):
* Bu veri kümesi, bireylerin kişisel ve yaşam tarzı faktörleriyle ilgili çeşitli özelliklerini içermektedir. Sağlık, yaşam tarzı ve sosyo-ekonomik durum gibi alanlarda analiz yapmayı kolaylaştırmak için tasarlanmıştır.

> Özellikler
* Name: Bireyin tam adı.
* Age: Bireyin yaşı (yıl cinsinden).
* Marital Status: Bireyin medeni durumu. Olası değerler: Single, Married, Divorced, Widowed.
* Education Level: Bireyin elde ettiği en yüksek eğitim seviyesi. Olası değerler: High School, Associate Degree, Bachelor's Degree, Master's Degree, PhD.
* Number of Children: Bireyin sahip olduğu çocuk sayısı.
* Smoking Status: Bireyin sigara içme durumu. Olası değerler: Smoker, Former, Non-smoker.
* Physical Activity Level: Bireyin yaptığı fiziksel aktivite düzeyi. Olası değerler: Sedentary, Moderate, Active.
* Employment Status: Bireyin istihdam durumu. Olası değerler: Employed, Unemployed.
* Income: Bireyin yıllık geliri (USD cinsinden).
* Alcohol Consumption: Alkol tüketim düzeyi. Olası değerler: Low, Moderate, High.
* Dietary Habits: Bireyin diyet alışkanlıkları. Olası değerler: Healthy, Moderate, Unhealthy.
* Sleep Patterns: Uyku kalitesi. Olası değerler: Good, Fair, Poor.
* History of Mental Illness: Bireyin mental hastalık geçmişi olup olmadığı. Olası değerler: Yes, No.
* History of Substance Abuse: Bireyin madde bağımlılığı geçmişi olup olmadığı. Olası değerler: Yes, No.
* Family History of Depression: Ailede depresyon geçmişi olup olmadığını belirtir. Olası değerler: Yes, No.
* Chronic Medical Conditions: Bireyin kronik tıbbi durumları olup olmadığını belirtir. Olası değerler: Yes, No.

> Kullanım Alanları
* Bu veri kümesi, çeşitli sağlık, yaşam tarzı ve sosyo-ekonomik faktörlerin analizinde kullanılmak üzere tasarlanmıştır. Predictive modeling (tahmin modelleri), clustering (kümeleme) ve exploratory data analysis (keşifsel veri analizi) gibi görevler için uygundur.

# 1. Kütüphaneleri Yükleme İşlemi
"""

import numpy as np    #Sayısal hesaplamalar ve veri manipülasyonu için kullanılır.
                      #Diziler ve çok boyutlu dizilerle çalışmayı kolaylaştırır.
                      #Hızlı ve verimli vektör operasyonları ve çeşitli matematiksel fonksiyonlar sağlar.

import pandas as pd   #Veri okuma, temizleme, analiz etme ve işleme için kullanılır.

import os             #Dosya ve dizin işlemlerini yapabilmek için kullanılır.
                      #Dosyaların bulunduğu dizini değiştirme veya mevcut dosyaları listeleme vb.
                      #Sistemle etkileşime geçip dosya yollarını yönetmenizi sağlar.

import seaborn as sns #İstatistiksel veri görselleştirmeleri yapar. Matplotlib üzerine kuruludur.
                      #Gelişmiş ve estetik grafikleri oluşturmanızı sağlar.
                      #Veri dağılımını, ilişkilerini ve kategorik verileri gösteren grafikler oluşturmak için kullanılır.

import matplotlib.pyplot as plt #Temel ve esnek veri görselleştirmeleri yapar.

import plotly.express as px #Etkileşimli ve dinamik grafikler oluşturur. Kullanıcıların grafiklerle etkileşime girmesini sağlayan güçlü bir araçtır.
                            #3D grafikler, coğrafi haritalar ve hareketli grafikler gibi ileri seviye görselleştirmeleri destekler.

#Eksik veri analizi için ve giderilmesi için
import missingno as msno

# Gerekli modüller ve ayarlar
import warnings  # Uyarıları kontrol etmek için warnings modülü kullanılır.
warnings.filterwarnings("ignore")  # Tüm uyarıları gizlemek için kullanılır.

# Matplotlib'te grafik stili ayarları
from matplotlib import style  # Grafik stillerini değiştirmek için style modülü.
style.use("ggplot")  # ggplot stilini uygular. Bu stil, modern ve estetik bir görünüm sağlar.

"""# 2.Veri Setini Yükleme İşlemi ve Veri Hakkında Bilgiler"""

# Veri setini yükle
df_ = pd.read_csv("/kaggle/input/depression-dataset/depression_data.csv")
#Bu satırda, dosyadaki veriler, pandas kütüphanesi kullanılarak okunur ve df değişkenine atanır.
#Artık df üzerinden çeşitli analizler ve işlemler yapılabilir.
df = df_.copy()

df.info()
# Veri çerçevesi hakkında daha detaylı bilgiler sunar.
#Her sütunun veri tipi, veri tiplerinin sayısal dağılımı, bellek kullanımı, eksik değerler ve sütunların ve satırların kaç olduğu bilgisini görürüz.

df.columns #Pandas'ta bir veri çerçevesinin sütun etiketlerine erişim sağlayan bir özniteliktir.
           #DataFrame'deki sütunların adlarını temsil eden bir Index döndürür.

#satır_sayısı, sütun_sayısı
df.shape

df.head(10) #Bu fonksiyon, DataFrame'in ilk 10 satırını gösterir. Ancak, içine bir sayı parametresi verirseniz, o kadar satır döndürür.

df.tail(10) #Veri setinin varsayılan olarak son 10 satıra baktık.

df.describe()
#count: Sütundaki non-null (boş olmayan) değerlerin sayısı.
#mean: Sütundaki değerlerin ortalaması.
#std: Sütundaki değerlerin standart sapması.
#min: Sütundaki en küçük değer.
#25%: Alt çeyrek yüzdesi, sütundaki değerlerin %25'inin altında olan değer.
#50%: Medyan veya ortanca, sütundaki değerlerin yarısından küçük ve yarısından büyük olan değer.
#75%: Üst çeyrek yüzdesi, sütundaki değerlerin %75'inin altında olan değer.
#max: Sütundaki en büyük değer.

df.isnull().sum() #Eksik (Null) değerlerin toplamı

df.duplicated().sum() #Tekrarlayan satır sayısı

categorical_features = []
numerical_features = []

for col in df.columns:
    if (df[col].dtype == "object") or (df[col].dtype == "categorical"):
        categorical_features.append(col)
    else:
        numerical_features.append(col)

categorical_features, numerical_features

"""# 3. Veri Setinde Yapay Olarak Eksik Değerler Oluşturma"""

# Veri setinde rasgele eksik veriler oluşturalım.

import random

def add_random_missing_values(dataframe: pd.DataFrame,
                              missing_rate: float = 0.05,
                              seed: random = 42) -> pd.DataFrame:
    """Turns random values to NaN in a DataFrame.

    To use this function, you need to import pandas, numpy and random libraries.

    Args:
        dataframe (pd.DataFrame): DataFrame to be processed.
        missing_rate (float): Percentage of missing value rate in float format. Defaults 0.05


    """
    # Get copy of dataframe
    df_missing = dataframe.copy()

    # Obtain size of dataframe and number total number of missing values
    df_size = dataframe.size
    num_missing = int(df_size * missing_rate)

    # Set seed
    if seed:
        random.seed(seed)

    # Get random row and column indexes to turn them NaN
    for _ in range(num_missing):
        row_idx = random.randint(0, dataframe.shape[0] - 1)
        col_idx = random.randint(0, dataframe.shape[1] - 1)

        df_missing.iat[row_idx, col_idx] = np.nan

    return df_missing

df = add_random_missing_values(dataframe = df,
                               missing_rate = 0.03)

"""# 4. Eksik Veri Analizi


Veri seti içerisinde eksik değerler bulunması yapısal bir bozukluğa işaret eder ve mutlaka uygun yöntemlerle ele alınmalıdır.

Eksik veriler, duruma bağlı olarak veri setinden silinebilir veya uygun veriler ile doldurulabilir. Ancak eksik verilerin silinmesi, silinen satır veya sütunlar içerisinde yer alan diğer verilerin kaybedilmesi anlamına gelir. Eksik verilerin doldurulması işleminde ise, veri setine sentetik bir girdi yapacağımızdan dolayı, doldurma işlemleri veri setindeki dağılımları manipüle edebilir (veri setinde yanlılık oluşturabilir).

Eksik verilerin ne sebeple ortaya çıktığı hassas bir şekilde değerlendirilmeli, nasıl ele alınacağı da bu değerlendirme sonucunda uygun şekilde karar verilmelidir.
"""

df.columns[df.isnull().any()] #Eksik deger olup olmadigini kontrol edecegiz.

df.isnull().sum() #Eksik deger olup olmadigini tespit ediyoruz.

df.isna().sum() # -> isnull() methodu yerine isna()  methodu da kullanılabilir.

# Eksik olmayan değerlerin sayısı
df.notnull().sum()

# Veri setinde toplam kaç adet eksik gözlem var, kaç adet eksik olmayan gözlem var görelim.
print(f"Veri seti içerisinde toplam {df.notnull().sum().sum()} adet eksik olmayan, {df.isnull().sum().sum()} eksik gözlem var.")

# Veri setinde en az bir gözlemi eksik olan kayıtlara da ulaşabiliriz.
df[df.isnull().any(axis = 1)]

# Hiç eksik gözlemi bulunmayan kayıtları getirelim.
df[df.notnull().all(axis = 1)][:5]

#!pip install missingno -> missingno kütüphanesini kullanabilmek için öncelikle yüklemeniz lazım.
import missingno as msno

msno.bar(df = df,
         figsize = (8, 4),
         fontsize = 10);

# msno.matrix(), değişkenlerde bulunan eksik değerlerin ilişkili olup olmadığını görsel yolla tespit etmek için kullanılabilir.
msno.matrix(df = df[['Age', 'Number of Children', 'Income']],
            figsize = (10, 6),
            fontsize = 10);

# Nullity Correlation (Heatmap)
# 1'e ne kadar yakınsa, ilişki ihtimali o kadar yüksek.
# 0 ise, birbirlerini etkileyen bir durum yoktur.
msno.heatmap(df = df,
             figsize = (10, 6),
             fontsize = 10);

"""# 4.2 Yöntem 1: Eksik Verilerin Silinmesi
Veri setinde bulunan eksik verilere müdahale yöntemlerinden birisi, eksik verilerin silinmesidir. Uygulaması oldukça kolay bir yöntem olsa da eksik verileri silmeden önce dikkat edilmesi gereken önemli hususlar vardır.

Eksik bir verinin bulunduğu gözlemi silmeya karar verebilmek için, bu eksikliğin doğal olmayan bir şekilde ortaya çıktığından emin olmamız gerekir. Örneğin elimizdeki bir araç veri setinde elektrikli araçlar için motor hacmi kolonunda Na değer bulunması doğal bir eksikliğe işaret eder. Bu durumda silme işlemi yerine uygun bir şekilde doldurmak tercih edilebilir.

Eksik veriler veri setinde kayda değer bir yüzdeyi oluşturuyorsa, eksik verilerin silinmesi durumunda veri setindeki birçok gözlemi kaybedeceğimiz unutulmamalıdır. Bu durumda veri seti içerisinde bize bilgi sağlayabilecek birçok veriyi de kaybetmiş olacağız. Verinin olabildiğince fazla olması, hem analitik yöntemler hem de makine öğrenmesi yöntemleri için oldukça önemli olduğuna göre, veri setinden olabildiğince az kayıp verecek yöntemler denemeliyiz.
"""

# Eksik verilerin dropna ile silinmesi.
# Kalıcı bir değişiklik yapmaz, bunu yapmak için inplace argümanı kullanılmalı veya atama yapılmalıdır.

df.dropna(inplace = False)[:5]
#df = df.dropna()

# Sadece bütün değerleri eksik olan bir gözlemi silmek istersek;
df.dropna(how = 'all')[:5]

# Değişken bazında silmek için;
df.dropna(axis = 1)

"""# 4.3 Yöntem 2: Eksik Verilerin Doldurulması
Eksik verilerin doldurulması kararı, silinmesi işleminde olduğu gibi hassas ve bilinçli bir şekilde değerlendirilmesi gereken bir karardır. Zira doldurma işlemi veride gürültü (noise) oluşturabilir ve verinin istatistiksel olarak güvenilirliğini zedeleyebilir. Analitik durumlar içinse yanlış bilgi çıkarımlarına sebebiyet verebilir. Bu nedenle en sağlıklı doldurma kararının alındığı durumlarda dahi bu yanlılık durumu mutlaka göz önünde bulundurulmalıdır.
"""

# Doldurma işlemlerini gerçekleştirmek için veri setimin bir kopyasını oluşturuyorum.
df_fillna = df.copy()

df_fillna.head(3)

df_fillna.isna().sum()

"""# 4.3.1 Sayısal Değişkenlerin Doldurulması"""

# Numerik bir değişkenin mean değeriyle doldurulması
mean_Age = df_fillna['Age'].mean()

df_fillna['Age'].fillna(value = mean_Age, inplace = True)

df_fillna.isna().sum()

# Doldurma işleminin döngüyle yapılması
to_be_filled = numerical_features[1:]

for col in to_be_filled:
    df_fillna[col].fillna(df[col].mean(), inplace = True)

df_fillna.isna().sum()

df.describe().T

# Bir sayısal değişkenin dağılımını görmek için histogram kullanabiliriz.
plt.hist(df['Age'])
plt.show()

"""# 4.3.2 Kategorik Değişkenlerin Doldurulması"""

# Name değişkeninde toplam kaç adet eksik değer olduğunu görelim.
print(df_fillna['Name'].isna().sum())

# Name değişkeninde en çok tekrar eden değeri (mode) alalım.
name_mode = df_fillna['Name'].mode()

# Name değişkenini mode değeri ile dolduralım.
df_fillna['Name'] = df_fillna['Name'].fillna(value=name_mode[0])

# Name değişkeninde toplam kaç adet eksik değer olduğunu tekrar görelim.
print(df_fillna['Name'].isna().sum())

# History of Mental Illness değişkeninde toplam kaç adet eksik değer olduğunu görelim.
print(df_fillna['History of Mental Illness'].isna().sum())

# History of Mental Illness değişkeninde en çok tekrar eden değeri (mode) alalım.
mental_illness_mode = df_fillna['History of Mental Illness'].mode()

# History of Mental Illness değişkenini mode değeri ile dolduralım.
df_fillna['History of Mental Illness'] = df_fillna['History of Mental Illness'].fillna(value=mental_illness_mode[0])

# History of Mental Illness değişkeninde toplam kaç adet eksik değer olduğunu tekrar görelim.
print(df_fillna['History of Mental Illness'].isna().sum())

df_fillna[["Physical Activity Level"]][:20]

# Önceki değer ile doldurma işlemi
df_fillna["Physical Activity Level"].fillna(method = "bfill")

# Sonraki değer ile doldurma işlemi
df_fillna["Physical Activity Level"].fillna(method = "ffill")

"""# 4.3.3 Kategorik Kırılım İle Doldurma İşlemi
Burada basitçe mean ve median değerler ile doldurma işlemi yapmış olsak da, eksik veri durumunu bu kadar basit bir şekilde ele almak her zaman doğru olmayacaktır. Bu tarz basit doldurma işlemleri hızlı bir çözüm olarak ele alınmalıdır. Daha analitik bir yaklaşım için veri içerisinde benzetimler uygulayarak doldurma işlemlerini buna göre gerçekleştirebiliriz.ur.ur.
"""

df_categorical_fillna = df.copy()

df_categorical_fillna.isna().sum()

df_categorical_fillna["Age"].fillna(value = df_categorical_fillna.groupby("History of Mental Illness")["Age"].transform("mean"),
                                       inplace = True)

df_categorical_fillna.isna().sum()

df_categorical_fillna[df_categorical_fillna[["History of Mental Illness", "Age"]].isna().all(axis=1)][["History of Mental Illness", "Age"]]

df_categorical_fillna[df_categorical_fillna['Age'].isnull()]

"""# 4.3.4 Makine Öğrenmesi ile Değer Atama Teknikleri
Makine öğrenmesi yöntemleri kullanarak da eksik verileri doldurmak mümkündür. Makine Öğrenmesi modelleri bu bootcamp'in konusu olmadığı için detaylı bir anlatım gerçekleştirilmeyecektir.

Hangi yöntemler kullanılabilir?:

KNNImputer (K-Nearest Neighbor)
Random Forest Classifier
Google -> "How can I fill missing values by using Machine Learning techniques in Python?", "Python ile eksik verileri Makine Öğrenmesi teknikleri kullanarak nasıl doldurabilirim?"

# 5. Kategorik Değişken Analizi
"""

df = df_.copy()
df.info()

"""# 5.1 Kategorik Değişken İşlemleri"""

# Spesifik bir veri tipi tutan değişkenleri seçmek için select_dtypes() kullanabiliriz.
df_categorical = df.select_dtypes(include = "object")
df_categorical.head(3)

# Kategorik bir değişkendeki benzersiz değerleri gözlemlemek için unique() kullanabiliriz.
df_categorical["Education Level"].unique()

# Kategorik değişkenlerdeki benzersiz değerlerin sayısını görebilmek için nunique() kullanabiliriz.
for col in df_categorical.columns:
    print(f'There are {df_categorical[col].nunique()} unique values in "{col}" categorical feature.\n')

# Her bir kategorik değişken için toplam gözlem sayısını value_counts() ile buluyoruz.
for col in df_categorical.columns:
    print(f'{df_categorical[col].value_counts()}\n', 5*"*********")

# Kategorik bir değişkende bulunan kategorik değerleri bir liste haline getirip sonra kullanabiliriz.
comp_categories = df["Sleep Patterns"].unique().tolist()[::-1]
comp_categories

from pandas.api.types import CategoricalDtype

df["Sleep Patterns"] = df["Sleep Patterns"].astype(CategoricalDtype(categories = comp_categories, ordered = True))

df["Sleep Patterns"].head()

# Dataframe summary

def summary(df):
    print(f'data shape: {df.shape}')
    summ = pd.DataFrame(df.dtypes, columns=['Data Type'])
    summ['Missing#'] = df.isna().sum()
    summ['Missing%'] = (df.isna().sum())/len(df)
    summ['Dups'] = df.duplicated().sum()
    summ['Uniques'] = df.nunique().values
    summ['Count'] = df.count().values
    desc = pd.DataFrame(df.describe(include='all').transpose())
    summ['Min'] = desc['min'].values
    summ['Max'] = desc['max'].values
    summ['Average'] = desc['mean'].values
    summ['Standard Deviation'] = desc['std'].values
    summ['First Value'] = df.loc[0].values
    summ['Second Value'] = df.loc[1].values
    summ['Third Value'] = df.loc[2].values

    display(summ)

summary(df)

"""# 5.2 Kategorik Değişkenlerde Görselleştirme İşlemleri"""

# Kategorik bir değişkendeki kategorilerin gözlem sayılarını basitçe görselleştirelim.
df['Marital Status'].value_counts().plot.barh();

sns.countplot(data = df,
              y = "Marital Status",
              hue = "Marital Status",
              order = df["Marital Status"].value_counts().index,
              palette = "Set1");

"""**sigara içenler**"""

smokers = df["Smoking Status"].value_counts()
smokers

smokers_df = smokers.reset_index()
smokers_df.columns = ['Smoking Status', 'Total Value']
plt.figure(figsize=(14,7))
smok_plot = sns.barplot(x="Smoking Status", y="Total Value", data=smokers_df,palette='viridis')
for i, value in enumerate(smokers_df['Total Value']):
    plt.text(i, value + 2, f'{value}', ha='center', color='black', fontsize=11, fontweight='bold')
plt.title("Smokers Data", weight='bold', fontsize=16, color='navy')
plt.xlabel("Smokers Types", fontsize=12, color='darkblue')
plt.ylabel("People", fontsize=12, color='darkblue')

plt.gca().set_facecolor('whitesmoke')
plt.show()

sns.catplot(data = df,
            x = "Alcohol Consumption",
            y = "Age");

plt.figure(figsize = (15, 8))
sns.barplot(data = df,
            x = "Marital Status",
            y = "Income",
            hue = "Education Level");

"""# 5.3 Kategorik Gruplama (groupby) İşlemleri"""

df_usd = df.groupby(by = "Physical Activity Level")["Income"].mean().to_frame().reset_index().sort_values(by = "Income", ascending = False)

df_usd

df.groupby(by = ['Physical Activity Level', 'Alcohol Consumption'])['Income'].mean().to_frame().reset_index().sort_values(by = "Income", ascending = False)[:5]

plt.figure(figsize = (12, 8))
plt.xticks(rotation = 90)
sns.barplot(data = df, x = "Sleep Patterns", y = "Number of Children", hue = "Physical Activity Level");

# Marital Status'a göre Physical Activity Level dağılımını alıyoruz
df_status = (
    df.groupby(by="Marital Status")["Physical Activity Level"]
    .value_counts()
    .to_frame(name="Counts")  # 'Counts' adında yeni bir sütun oluşturuyoruz
    .reset_index()
)

# Bekar bireyler için filtreleme
df_status = df_status[df_status["Marital Status"] == "Single"]

# Sonuçları görmek
print(df_status)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

# Barplot
sns.barplot(
    data=df_status,
    x="Physical Activity Level",  # X eksenine fiziksel aktivite seviyelerini koyuyoruz
    y="Counts",                   # Y eksenine dağılım sayısını koyuyoruz
    palette="viridis"             # Renk paleti seçimi
)

plt.title("Physical Activity Level Distribution for Single Individuals")
plt.xlabel("Physical Activity Level")
plt.ylabel("Counts")
plt.xticks(rotation=45)
plt.show()

"""# 6. Sürekli Değişken Analizi

# 6.1 Sürekli Değişkenlerin İncelenmesi
"""

# Veri setindeki numerik kolonları seçmek için aşağıdaki yapıyı kullanabiliriz.
df_numerical = df.select_dtypes(include = ["float64", "int64"])
df_numerical.head()

df_numerical.describe().T

# Bir veri setindeki numerik kolonların istatistiksel bilgilerine erişmek için basitçe bu tarz bir fonksiyon yazabiliriz.

def give_stats(dataframe: pd.DataFrame) -> None:
    """Prints statistical information for numerical columns.

    Args:
        dataframe (pd.DataFrame): DataFrame object.

    Return:
        None

    """

    num_df = dataframe.select_dtypes(include = ["float", "int"])

    for col in num_df.columns:
        print(f"**********{col}**********")
        print(f"Mean value of {col} is {num_df[col].mean():.2f}")
        print(f"Std value of {col} is {num_df[col].std():.2f}")
        print(f"Max value of {col} is {num_df[col].max()}")
        print(f"Min value of {col} is {num_df[col].min()}")
        print(f"Count value of {col} is {num_df[col].count()}")
        print(f"Median value of {col} is {num_df[col].median()}\n")
give_stats(dataframe = df)

# Numerik bir kolonun dağılımını görmek için histogram kullanırız.
sns.histplot(data = df, x = "Income", kde = True, hue = "Chronic Medical Conditions");

# kdeplot ise ilgili numerik değişkenin yoğunluğunu gösterir.
sns.kdeplot(df['Income'], fill = True);

# FacetGrid kullanarak kategorik kırılımda yoğunluk gözlemleyebiliriz.
sns.FacetGrid(data = df,
              hue = "Education Level",
              height = 7,
              xlim = (0, 400000)).map(sns.kdeplot, "Income", fill = True).add_legend();

# Catplot ile numerik bir değişkenin kategorik bazda ve kırılımdaki dağılımını görebiliriz.
plt.figure(figsize = (12, 8))
sns.catplot(data = df, x = "Dietary Habits", y = "Age", hue = "Physical Activity Level", kind = "point");

# Boxplot kategorik olarak numerik dağılımı gösterir, çeyreklik değerler ve IQR'a göre aykırı değerler de boxplot ile gözlemlenebilir.
sns.boxplot(data = df,
            x = "Smoking Status",
            y = "Income",
            hue = "Education Level");

# Farklı numerik görselleştirme işlemleri için iris veri setini yükleyelim.
iris = sns.load_dataset(name = "iris")
iris[:3]

# pairplot numerik değişkenler arasındaki saçılım ve yoğunluk ilişkilerini gösterir.
sns.pairplot(data = iris, hue = "species");

# Scatter Plot, numerik değişkenler arasındaki saçılım ilişkisini gösterir.
sns.scatterplot(data = iris,
                x = "sepal_width",
                y = "sepal_length",
                hue = "species");

# Heatmap ise corr() (korelasyon) methodu ile kullanıldığında numerik değerler arasındaki ilişki kuvvetini gösterir.
plt.figure(figsize = (10, 7))
sns.heatmap(iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].corr(), annot = True, cmap = "coolwarm");

# Çizgi grafik ile numerik değişkenlerin tarihsel olarak değişimini gözlemleyebiliriz.
plt.figure(figsize = (10, 8))
sns.lineplot(data = df,
             x = "Number of Children",
             y = "Income",
             hue = "Marital Status");
# Yarı saydam alanlar, güven aralığını (confidence interval) temsil eder.

"""# 7. Aykırı Değer Analizi (Outliers)
Aykırı değerlerin analizi de tıpkı eksik verilerde olduğu gibi hassasiyetle değerlendirilmelidir. Aykırı değerlerin varlığı veri setindeki dağılımları etkileyeceği için, aykırı değere sahip bir veri setiyle tahmin modeli oluşturduğumuzda modelimizin genellenebilirliğinin düşmesine sebep olacaktır.

Aykırı değerlerin değerlendirilmesi için sektörel bilgi, standart sapma yaklaşımı, Z-skoru, IQR yöntemi gibi yöntemler kullanılabilir. Biz burada IQR yöntemi ile basitçe bir düzeltme işlemi uygulayacağız.
"""

df = df_.copy()

# Bir değişkendeki IQR'a göre aykırı gözlemleri boxplot kullanarak görselleştirelim.
plt.figure(figsize = (8, 6))
sns.boxplot(data = df,
            y = df["Income"],
            orient = "v");

df_income = df['Income']
df_income

# Quantile değerlerin belirlenmesi.
Q1 = df_income.quantile(0.25)
Q3 = df_income.quantile(0.75)

print(Q1)
print(Q3)

# IQR değerin belirlenmesi.
IQR = Q3-Q1
print(IQR)

# Alt ve üst sınırların belirlenmesi.
lower_fence = Q1 - 1.5*IQR
upper_fence = Q3 + 1.5*IQR

# Upper_fence üzerinde kalan aykırı gözlemlerin index değerlerini, daha sonra kullanmak üzere bir değişkende tutabiliriz.
outlier_idx = df_income[df_income > upper_fence].index

outlier_idx

df_income[df_income > upper_fence]

"""# 7.1 Aykırı Gözlemlerin Silinmesi"""

df_del = df[~(df_income > upper_fence)]

df_del

plt.figure(figsize = (8, 6))
sns.boxplot(data = df_del,
            y = df_del["Income"],
            orient = "v");

"""# 7.2 Aykırı Gözlemlerin Doldurulması

# 7.2.1 Ortalama Değer İle Doldurma
"""

df.loc[df_income > upper_fence, "Income"] = df_income.mean()

df.loc[df_income > upper_fence, "Income"]

plt.figure(figsize = (8, 6))
sns.boxplot(data = df_del,
            y = df["Income"],
            orient = "v");

"""# 7.2.2 Baskılama Yöntemi"""

df = df_.copy()

df.loc[df_income > upper_fence, "Income"] = upper_fence

plt.figure(figsize = (8, 6))
sns.boxplot(data = df_del,
            y = df["Income"],
            orient = "v");

"""8. Feature Engineering"""

df.head()

from sklearn.preprocessing import LabelEncoder  # LabelEncoder sınıfını içe aktarır
lb = LabelEncoder()  # LabelEncoder nesnesini oluşturur
objList = df.select_dtypes(include="object").columns
for obj in objList:
    df[obj] = lb.fit_transform(df[obj].astype(str))

corr = df.corr()
mask = np.triu(np.ones_like(corr, dtype=bool))
sns.set(rc={'figure.figsize': (20, 12)})

sns.heatmap(corr, mask=mask, cmap="coolwarm", annot=True, fmt=".2f")

# Correlations

limit = -1.0

data = df.corr()["Chronic Medical Conditions"].sort_values(ascending=False)
indices = data.index
labels = []
corr = []
for i in range(1, len(indices)):
    if data[indices[i]]>limit:
        labels.append(indices[i])
        corr.append(data[i])
sns.barplot(x=corr, y=labels)
plt.title('Correlations with "Chronic Medical Conditions"')
plt.show()

"""EDA"""

df_yes = df[df['Chronic Medical Conditions'] == 'Yes']
df_no = df[df['Chronic Medical Conditions'] == 'No']


def cat_summary(dataframe, col_name, plot=False):
    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                        "Ratio(%)": 100 * dataframe[col_name].value_counts() / len(dataframe),
                        "Yes(%)": 100 *df_yes.groupby(col_name)[col_name].value_counts() / len(df_yes),
                        "No(%)": 100 * df_no.groupby(col_name)[col_name].value_counts() / len(df_no)}))

    if plot:
        fig, axs = plt.subplots(1, 2, figsize=(8, 6))
        plt.subplot(1, 2, 1)
        sns.countplot(x=dataframe[col_name], data=dataframe)
        plt.title("Frequency of " + col_name)
        plt.xticks(rotation=90)

        plt.subplot(1, 2, 2)
        values = dataframe[col_name].value_counts()
        plt.pie(x=values, labels=values.index, autopct=lambda p: '{:.2f}% ({:.0f})'.format(p, p/100 * sum(values)))
        plt.title("Frequency of " + col_name)
        plt.legend(labels=['{} - {:.2f}%'.format(index, value/sum(values)*100) for index, value in zip(values.index, values)],
                   loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=1)
        plt.show(block=True)

def num_summary(dataframe, numerical_col, plot=False):

    if plot:
            fig, axs = plt.subplots(1, 2, figsize=(10, 5))
            plt.subplot(1, 2, 1)
            dataframe[numerical_col].hist(bins=50)
            plt.xlabel(numerical_col)
            plt.title(numerical_col)

            plt.subplot(1, 2, 2)
            sns.boxplot(y=numerical_col, data=dataframe)
            plt.title("Frequency of " + numerical_col)
            plt.xticks(rotation=90)

            plt.show(block=True)

            print("______________________________________________________\n")

def target_summary_with_num(dataframe, target, numerical_col):
    print(dataframe.groupby(target).agg({numerical_col: "mean"}), end="\n\n\n")

"""Marital Status"""

cat_summary(df, "Marital Status", True)

fig, ax = plt.subplots(figsize=(12, 5))
sns.histplot(data=df, x="Marital Status", hue="Chronic Medical Conditions", multiple="fill")
plt.title("Marital Status", fontsize = 18)
plt.show()

"""Age"""

target_summary_with_num(df, "Chronic Medical Conditions", "Age")

num_summary(df, 'Age', plot=True)

fig, ax = plt.subplots(figsize=(12, 5))
sns.histplot(data=df, x="Age", hue="Chronic Medical Conditions", multiple="fill")
plt.title("Age", fontsize = 18)
plt.show()

"""Education Level"""

cat_summary(df, "Education Level", True)

fig, ax = plt.subplots(figsize=(12, 5))
sns.histplot(data=df, x="Education Level", hue="Chronic Medical Conditions", multiple="fill")
plt.title("Education Level", fontsize = 18)
plt.show()

"""Number od Children"""

target_summary_with_num(df, "Chronic Medical Conditions", "Number of Children")

num_summary(df, 'Number of Children', plot=True)

fig, ax = plt.subplots(figsize=(12, 5))
sns.histplot(data=df, x="Number of Children", hue="Chronic Medical Conditions", multiple="fill")
plt.title("Number of Children", fontsize = 18)
plt.show()

"""Smoking Status"""

cat_summary(df, "Smoking Status", True)

fig, ax = plt.subplots(figsize=(12, 5))
sns.histplot(data=df, x="Smoking Status", hue="Sleep Patterns", multiple="fill")
plt.title("Smoking Status", fontsize = 18)
plt.show()